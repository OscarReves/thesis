tokenizer_name: 
dump_path: data/wiki/dump
chunked_path: data/wiki/chunked_paragraph
splitter_name: paragraph

# for embedding 
index_path: data/wiki/index/index_paragraph
embedder_name: e5
device: cuda
batch_size: 1024

